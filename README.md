# deepseekchat README

This is a VScode extension meant to allow developers to chat with deepseek inside of VScode. I am building this to expand my knowlage on LLM integration, VScode extensions, and typescript vs javascript. This is also a project meant to show the power of free open source LLMs and how they can be integrated into a developer's enviroment.

## Features

this extension adds the `Deepseek Chat` command to VScode, which can be accessed through pressing `Ctrl + Shift + P`. This stats a windowed chat with deepseek where Deepseek will respond to what you prompt when the ask button is pressed.

## Requirements

In order to run this extension, you must have npm and ollama installed. It is also *highly* recomended that you run the model of deepseek you choose through the CLI of your choice beforehand.

## Using

This extension can be used in debug mode by pressing `f5` to begin debugging.

## Features planned to add

- Ability to switch between different models
- Option to switch think tokens on and off
- Option to allow for model to save history
- Option to include a file in conversation



## Known Issues

No known issues at this time. If issue is found, please submit an issue to this repository.

## Release Notes

Please Ignore Input color command. This is just a simple function to get me familiar with VScode's capabilities and will be taken out in future 

### 1.0.0

Initial release. Functionality for chatting with DeepSeek 1.5b model.



---



**Enjoy!**
